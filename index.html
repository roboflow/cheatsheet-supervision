<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<link rel="icon" href="./favicon.png" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		
		<link href="./_app/immutable/assets/0.DfyLXXRR.css" rel="stylesheet">
		<link href="./_app/immutable/assets/SvelteToast.DbLvtVfH.css" rel="stylesheet">
		<link href="./_app/immutable/assets/2.DEwXrmHr.css" rel="stylesheet">
		<link rel="modulepreload" href="./_app/immutable/entry/start.DVWeqw6R.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/entry.oF-uKr0e.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/scheduler.CR9fYKd2.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index.Br0CiCGi.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/paths.Cw8C0YB3.js">
		<link rel="modulepreload" href="./_app/immutable/entry/app.pbv2YX8K.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index.CM4teq7i.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/0.uUKy5FYS.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/SvelteToast.svelte_svelte_type_style_lang.khwlsV__.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/2.r8PhugpK.js"><title>Cheatsheet • Supervision</title><!-- HEAD_svelte-kd8jbd_START --><meta name="description" content="A cheatsheet for Roboflow Supervision, covering commonly used functions and features: model loading, annotation, object detection, segmentation, and keypoint detection."><meta name="keywords" content="Roboflow, Supervision, computer vision, cheatsheet, SvelteKit, annotation, detection, segmentation, keypoints"><meta name="author" content="Linas Kondrackis"><!-- HEAD_svelte-kd8jbd_END -->

		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@100..900&display=swap" rel="stylesheet">
	</head>
	<body data-sveltekit-preload-data="hover">
		<div style="display: contents">  <div class="svelte-17v9iqe"> <div class="justify-center w-full flex flex-col items-center gap-12 pb-4 px-6"><br> <div class="w-full max-w-[1123px] pb-2 flex flex-col bg-white page-root overflow-hidden rounded-lg svelte-1ngqj27"> <div class="h-1/2 flex justify-center flex-col items-center mb-2 py-1 px-6" data-svelte-h="svelte-h3jydf"><a href="https://supervision.roboflow.com/latest/" target="_blank" class="flex justify-center"><img src="./rf-supervision-cheatsheet-banner.png" alt="banner"></a> <div class="flex flex-col lg:flex-row text-sm justify-between w-full mt-2 gap-1"><span>Author:
        <a href="https://www.linkedin.com/in/linas-kondrackis/" class="underline text-[#8315F9]" target="_blank">Linas Kondrackis</a>
          Contributors:
        <a href="https://www.linkedin.com/in/bhavay2001/" class="underline text-[#8315F9]" target="_blank">Bhavay Malhotra</a>,
        <a href="https://www.linkedin.com/in/chris-doss-2a29ba1/" class="underline text-[#8315F9]" target="_blank">Chris Doss</a>
          </span> <span>supervision v0.21.0    July 2, 2024</span></div></div>  <div class="flex-grow flex flex-col lg:flex-row lg:justify-evenly"> <div class="lg:w-1/2 flex flex-col gap-4"><div slot="col1" class="p-6 flex flex-col gap-4"> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Basic Principles</h2> <div class="text-sm px-2 pb-2" data-svelte-h="svelte-e7fcwa"><p>Supervision simplifies the process of working with vision models. It offers connectors
            to popular model libraries, a plethora of visualizers (annotators), powerful
            post-processing features and an easy learning curve.</p> <ul class="w-full flex flex-col sm:flex-row mt-2 font-semibold !list-none gap-3 sm:flex-wrap mt-4 sm:justify-center sm:-ml-4 svelte-1ig1h5d"><li class="flex gap-2"><span class="text-[#8622FF] sm:hidden">»</span><span>Load image or video</span></li> <li class="flex gap-2"><span class="text-[#8622FF]">»</span> <span>Load the model</span></li> <li class="flex gap-2"><span class="text-[#8315F9]">»</span> <span>Run the model</span></li> <li class="flex gap-2"><span class="text-[#8315F9]">»</span> <span>Annotate</span></li></ul></div></div> <div class="mt-2"></div> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Quickstart</h2> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="bash" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->pip install supervision inference -q<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="bash" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->wget https://media.roboflow.com/notebooks/examples/dog.jpeg<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> supervision <span class="hljs-keyword">as</span> sv
<span class="hljs-keyword">from</span> inference <span class="hljs-keyword">import</span> get_model<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->image = cv2.imread(<span class="hljs-string">&quot;dog.jpeg&quot;</span>)
model = get_model(model_id=<span class="hljs-string">&quot;yolov8n-640&quot;</span>)
results = model.infer(image)[<span class="hljs-number">0</span>]
detections = sv.Detections.from_inference(results)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->annotated_image = sv.BoundingBoxAnnotator().annotate(
    scene=image.copy(), detections=detections
)
annotated_image = sv.LabelAnnotator().annotate(
    scene=annotated_image, detections=detections
)
sv.plot_image(annotated_image)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div></div></div>  <div class="border-slate-200 lg:border-l lg:w-1/2 flex flex-col gap-4"><div slot="col2"> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Core Concepts</h2> <ul class="list-disc list-inside ml-2 flex flex-col gap-1 svelte-1ig1h5d" data-svelte-h="svelte-f6nupx"><li><strong>sv.Detections</strong>: Common class for model both object detection and
            segmentation. Contains fields: <strong>xyxy</strong>, <strong>mask</strong>,
            <strong>class_id</strong>, <strong>tracker_id</strong>, <strong>data</strong>.</li> <li><strong>import supervision as sv</strong>: All useful functions available in global
            scope</li> <li><strong>A selection of models</strong>: Load
            <a href="https://inference.roboflow.com/quickstart/aliases/" class="underline text-[#8315F9]" target="_blank">popular</a>,
            <a href="https://inference.roboflow.com/quickstart/explore_models/" class="underline text-[#8315F9]" target="_blank">fine-tuned</a>, or
            <a href="https://inference.roboflow.com/quickstart/load_from_universe/" class="underline text-[#8315F9]" target="_blank">Universe</a> models.</li> <li><strong>sv.Detections.from_X</strong>: Load from one of
            <a href="https://supervision.roboflow.com/latest/detection/core/" class="underline text-[#8315F9]" target="_blank">12 sources.</a></li> <li><strong>Annotators</strong>: Draw the detections with one of
            <a href="https://supervision.roboflow.com/latest/detection/annotators/" class="underline text-[#8315F9]" target="_blank">20 annotators.</a></li> <li><strong>More features</strong>: This sheet contains &lt; 50% of supervision&#39;s features.
            Find others
            <a href="https://supervision.roboflow.com/latest/" class="underline text-[#8315F9]" target="_blank">here!</a></li></ul></div> <div class="mt-4"></div> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Read images &amp; Videos</h2> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">Load a single image</p> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">import</span> cv2
image = cv2.imread(<span class="hljs-string">&quot;dog.jpeg&quot;</span>)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">Iterate over video frames</p> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">for</span> frame <span class="hljs-keyword">in</span> sv.get_video_frames_generator(source_path=&lt;VIDEO_PATH&gt;):
    <span class="hljs-built_in">print</span>(frame.shape)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">Run a function over every frame, save output</p> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-keyword">def</span> <span class="hljs-title function_">callback</span>(<span class="hljs-params">scene: np.ndarray, index: <span class="hljs-built_in">int</span></span>) -&gt; np.ndarray:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Processing frame <span class="hljs-subst">{index}</span>&quot;</span>)
    <span class="hljs-keyword">return</span> scene;

sv.process_video(
    source_path=&lt;SOURCE_VIDEO_PATH&gt;,
    target_path=<span class="hljs-string">&quot;out.mp4&quot;</span>,
    callback=callback)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div></div></div></div> </div>  <div class="w-full max-w-[1123px] pb-2 flex flex-col bg-white page-root overflow-hidden rounded-lg svelte-1ngqj27"> <div class="bg-[#8622FF] text-white text-2xl font-inter font-bold p-6"><h1>Object Detection &amp; Segmentation</h1></div>  <div class="flex-grow flex flex-col lg:flex-row lg:justify-evenly"> <div class="lg:w-1/2 overflow-hidden"><div slot="col1" class="p-6 flex flex-col gap-4"><div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> supervision <span class="hljs-keyword">as</span> sv

image = cv2.imread(<span class="hljs-string">&quot;dog.jpeg&quot;</span>)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Frequent choices: Inference, Ultralytics &amp; Transfomers</h2> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">from</span> inference <span class="hljs-keyword">import</span> get_model

model = get_model(model_id=<span class="hljs-string">&quot;yolov8n-640&quot;</span>)
results = model.infer(image)[<span class="hljs-number">0</span>]
detections = sv.Detections.from_inference(results)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">from</span> ultralytics <span class="hljs-keyword">import</span> YOLO

model = YOLO(<span class="hljs-string">&quot;yolov8n.pt&quot;</span>)
results = model(image)[<span class="hljs-number">0</span>]
detections = sv.Detections.from_ultralytics(results)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DetrImageProcessor, DetrForObjectDetection

processor = DetrImageProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/detr-resnet-50&quot;</span>)
model = DetrForObjectDetection.from_pretrained(<span class="hljs-string">&quot;facebook/detr-resnet-50&quot;</span>)

image = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;dog.jpeg&quot;</span>)
inputs = processor(images=image, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)

<span class="hljs-keyword">with</span> torch.no_grad():
    outputs = model(**inputs)

target_size = torch.tensor([[image.size[<span class="hljs-number">1</span>], image.size[<span class="hljs-number">0</span>]]])
results = processor.post_process_object_detection(
    outputs=outputs, target_sizes=target_size)[<span class="hljs-number">0</span>]

detections = sv.Detections.from_transformers(
    transformers_results=results,
    id2label=model.config.id2label)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div> <div class="flex flex-row justify-center text-lg font-bold" data-svelte-h="svelte-bk5ia1"><a href="https://supervision.roboflow.com/latest/detection/core/" target="_blank" class="underline text-blue-500">+9 more connectors</a> ⚡</div></div></div>  <div class="border-slate-200 lg:border-l lg:w-1/2 overflow-hidden"><div slot="col2" class="p-6 flex flex-col gap-4"><div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Annotate Detection</h2> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->bounding_box_annotator = sv.BoundingBoxAnnotator()
label_annotator = sv.LabelAnnotator()

annotated_image = bounding_box_annotator.annotate(
    scene=image.copy(), detections=detections)
annotated_image = label_annotator.annotate(
    scene=annotated_image, detections=detections)

sv.plot_image(annotated_image)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="flex flex-row justify-center text-lg font-bold" data-svelte-h="svelte-1ivpez5"><a href="https://supervision.roboflow.com/latest/detection/annotators/" target="_blank" class="underline text-blue-500">+18 more annotators</a> 🎨</div></div> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Segmentation</h2> <div class="flex flex-row justify-center text-sm font-bold" data-svelte-h="svelte-j6dhss"><span>For <code class="svelte-1ig1h5d">inference</code> and <code class="svelte-1ig1h5d">ultralytics</code>, you only need to change the
            model ID:</span></div> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">from</span> inference <span class="hljs-keyword">import</span> get_model

model = get_model(model_id=<span class="hljs-string">&quot;yolov8n-seg-640&quot;</span>)
results = model.infer(image)[<span class="hljs-number">0</span>]
detections = sv.Detections.from_inference(results)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">from</span> ultralytics <span class="hljs-keyword">import</span> YOLO

model = YOLO(<span class="hljs-string">&quot;yolov8n-seg.pt&quot;</span>)
results = model(image)[<span class="hljs-number">0</span>]
detections = sv.Detections.from_ultralytics(results)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Annotate Segmentation</h2> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->mask_annotator = sv.MaskAnnotator()
label_annotator = sv.LabelAnnotator()

annotated_image = mask_annotator.annotate(
    scene=image.copy(), detections=detections)
annotated_image = label_annotator.annotate(
    scene=annotated_image, detections=detections)

sv.plot_image(annotated_image)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div></div></div></div> </div>  <div class="w-full max-w-[1123px] pb-2 flex flex-col bg-white page-root overflow-hidden rounded-lg svelte-1ngqj27"> <div class="bg-[#8622FF] text-white text-2xl font-inter font-bold p-6"><h1>Keypoints</h1></div>  <div class="flex-grow flex flex-col lg:flex-row lg:justify-evenly"> <div class="lg:w-1/2 overflow-hidden"><div slot="col1" class="p-6 flex flex-col gap-4"><div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> supervision <span class="hljs-keyword">as</span> sv

image = cv2.imread(<span class="hljs-string">&quot;dog.jpeg&quot;</span>)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Inference</h2> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">from</span> inference <span class="hljs-keyword">import</span> get_model

model = get_model(model_id=<span class="hljs-string">&quot;yolov8s-pose-640&quot;</span>)

results = model.infer(image)[<span class="hljs-number">0</span>]
key_points = sv.KeyPoints.from_inference(results)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Ultralytics</h2> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">from</span> ultralytics <span class="hljs-keyword">import</span> YOLO

model = YOLO(<span class="hljs-string">&quot;yolov8s-pose.pt&quot;</span>)

results = model(image)[<span class="hljs-number">0</span>]
key_points = sv.KeyPoints.from_ultralytics(results)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Yolo NAS</h2> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> super_gradients

device = <span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>
model = super_gradients.training.models.get(
    <span class="hljs-string">&quot;yolo_nas_pose_s&quot;</span>, pretrained_weights=<span class="hljs-string">&quot;coco_pose&quot;</span>).to(device)

results = model.predict(image, conf=<span class="hljs-number">0.1</span>)
key_points = sv.KeyPoints.from_yolo_nas(results)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div></div></div>  <div class="border-slate-200 lg:border-l lg:w-1/2 overflow-hidden"><div slot="col2" class="p-6 flex flex-col gap-4"><div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">⚠️ Available in pre-release: pip install git+https://github.com/roboflow/supervision.git@develop </p> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">import</span> mediapipe <span class="hljs-keyword">as</span> mp

image = cv2.imread(<span class="hljs-string">&quot;dog.jpeg&quot;</span>)
image_height, image_width, _ = image.shape
mediapipe_image = mp.Image(
    image_format=mp.ImageFormat.SRGB,
    data=cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

options = mp.tasks.vision.PoseLandmarkerOptions(
    base_options=mp.tasks.BaseOptions(
        model_asset_path=<span class="hljs-string">&quot;pose_landmarker_heavy.task&quot;</span>
    ),
    running_mode=mp.tasks.vision.RunningMode.IMAGE,
    num_poses=<span class="hljs-number">2</span>)

PoseLandmarker = mp.tasks.vision.PoseLandmarker
<span class="hljs-keyword">with</span> PoseLandmarker.create_from_options(options) <span class="hljs-keyword">as</span> landmarker:
    pose_landmarker_result = landmarker.detect(mediapipe_image)

key_points = sv.KeyPoints.from_mediapipe(
    pose_landmarker_result, (image_width, image_height))<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Annotate KeyPoints</h2> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->vertex_annotator = sv.VertexAnnotator(radius=<span class="hljs-number">10</span>)
edge_annotator = sv.EdgeAnnotator(thickness=<span class="hljs-number">5</span>)

annotated_frame = edge_annotator.annotate(
    scene=image.copy(),
    key_points=key_points
)
annotated_frame = vertex_annotator.annotate(
    scene=annotated_frame,
    key_points=key_points)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="flex flex-row justify-center text-lg font-bold" data-svelte-h="svelte-16kgnm"><a href="https://supervision.roboflow.com/latest/detection/annotators/" target="_blank" class="underline text-blue-500">+1 more annotator</a> 🎨</div></div></div></div></div> </div>  <div class="w-full max-w-[1123px] pb-2 flex flex-col bg-white page-root overflow-hidden rounded-lg svelte-1ngqj27"> <div class="bg-[#8622FF] text-white text-2xl font-inter font-bold p-6"><h1>What can supervision do?</h1></div>  <div class="flex-grow flex flex-col lg:flex-row lg:justify-evenly"> <div class="lg:w-1/2 overflow-hidden"><div slot="col1" class="p-6 flex flex-col gap-4"><div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> supervision <span class="hljs-keyword">as</span> sv
<span class="hljs-keyword">from</span> inference <span class="hljs-keyword">import</span> get_model<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Track Object Movement</h2> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->video_info = sv.VideoInfo.from_video_path(video_path=&lt;VIDEO_PATH&gt;)
frames_generator = sv.get_video_frames_generator(source_path=&lt;VIDEO_PATH&gt;)

model = get_model(<span class="hljs-string">&quot;yolov8s-640&quot;</span>)
tracker = sv.ByteTrack(frame_rate=video_info.fps)
smoother = sv.DetectionsSmoother()

trace_annotator = sv.TraceAnnotator()

<span class="hljs-keyword">with</span> sv.VideoSink(target_path=<span class="hljs-string">&quot;out.mp4&quot;</span>, video_info=video_info) <span class="hljs-keyword">as</span> sink:
    <span class="hljs-keyword">for</span> frame <span class="hljs-keyword">in</span> frames_generator:
        results = model.infer(frame)[<span class="hljs-number">0</span>]
        detections = sv.Detections.from_inference(results)
        detections = tracker.update_with_detections(detections)
        detections = smoother.update_with_detections(detections)

        annotated_frame = trace_annotator.annotate(
            frame.copy(), detections)

        sink.write_frame(frame=frame)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Count objects crossing a LineZone</h2> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->frames_generator = sv.get_video_frames_generator(source_path=&lt;VIDEO_PATH&gt;)
model = get_model(<span class="hljs-string">&quot;yolov8s-640&quot;</span>)
tracker = sv.ByteTrack()

start, end = sv.Point(x=<span class="hljs-number">0</span>, y=<span class="hljs-number">500</span>), sv.Point(x=<span class="hljs-number">200</span>, y=<span class="hljs-number">1000</span>)
line_zone = sv.LineZone(start=start, end=end)

<span class="hljs-keyword">for</span> frame <span class="hljs-keyword">in</span> frames_generator:
    results = model.infer(frame)[<span class="hljs-number">0</span>]
    detections = sv.Detections.from_inference(results)
    detections = tracker.update_with_detections(detections)
    crossed_in, crossed_out = line_zone.trigger(detections)
<span class="hljs-built_in">print</span>(line_zone.in_count, line_zone.out_count)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div></div></div>  <div class="border-slate-200 lg:border-l lg:w-1/2 overflow-hidden"><div slot="col2" class="p-6 flex flex-col gap-4"><div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Detect Small Objects</h2> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">InferenceSlicer breaks the image into small parts and runs the model on each one</p> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> supervision <span class="hljs-keyword">as</span> sv
<span class="hljs-keyword">from</span> inference <span class="hljs-keyword">import</span> get_model

image = cv2.imread(<span class="hljs-string">&quot;dog.jpeg&quot;</span>)
model = get_model(<span class="hljs-string">&quot;yolov8s-640&quot;</span>)

<span class="hljs-keyword">def</span> <span class="hljs-title function_">callback</span>(<span class="hljs-params">image_slice: np.ndarray</span>) -&gt; sv.Detections:
    results = model.infer(image_slice)[<span class="hljs-number">0</span>]
    <span class="hljs-keyword">return</span> sv.Detections.from_inference(results)

slicer = sv.InferenceSlicer(
    callback=callback,
    overlap_filter_strategy=sv.OverlapFilter.NON_MAX_SUPPRESSION,
)

detections = slicer(image)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Count objects inside PolygonZone</h2> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->frames_generator = sv.get_video_frames_generator(source_path=&lt;VIDEO_PATH&gt;)
model = get_model(<span class="hljs-string">&quot;yolov8s-640&quot;</span>)
tracker = sv.ByteTrack()

polygon = np.array([[<span class="hljs-number">100</span>, <span class="hljs-number">200</span>], [<span class="hljs-number">200</span>, <span class="hljs-number">100</span>], [<span class="hljs-number">300</span>, <span class="hljs-number">200</span>], [<span class="hljs-number">200</span>, <span class="hljs-number">300</span>]])
polygon_zone = sv.PolygonZone(polygon=polygon)

<span class="hljs-keyword">for</span> frame <span class="hljs-keyword">in</span> frames_generator:
    results = model.infer(frame)[<span class="hljs-number">0</span>]
    detections = sv.Detections.from_inference(results)
    detections = tracker.update_with_detections(detections)
    is_detections_in_zone = polygon_zone.trigger(detections)
    <span class="hljs-built_in">print</span>(polygon_zone.current_count)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div></div></div></div> </div>  <div class="w-full max-w-[1123px] pb-2 flex flex-col bg-white page-root overflow-hidden rounded-lg svelte-1ngqj27"> <div class="bg-[#8622FF] text-white text-2xl font-inter font-bold p-6"><h1>What can supervision do? (continued)</h1></div>  <div class="flex-grow flex flex-col lg:flex-row lg:justify-evenly"> <div class="lg:w-1/2 overflow-hidden"><div slot="col1" class="p-6 flex flex-col gap-4"><div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Save Detections to CSV</h2> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->frames_generator = sv.get_video_frames_generator(&lt;VIDEO_PATH&gt;)
model = get_model(<span class="hljs-string">&quot;yolov8s-640&quot;</span>)

csv_sink = sv.CSVSink(<span class="hljs-string">&quot;out.csv&quot;</span>)
<span class="hljs-keyword">with</span> csv_sink <span class="hljs-keyword">as</span> sink:
    <span class="hljs-keyword">for</span> frame <span class="hljs-keyword">in</span> frames_generator:
        results = model.infer(frame)[<span class="hljs-number">0</span>]
        detections = sv.Detections.from_inference(results)
        sink.append(
            detections, custom_data={<span class="hljs-string">&quot;&lt;YOUR_LABEL&gt;&quot;</span>:<span class="hljs-string">&quot;&lt;YOUR_DATA&gt;&quot;</span>})<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Save Detections to JSON</h2> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->frames_generator = sv.get_video_frames_generator(&lt;VIDEO_PATH&gt;)
model = get_model(<span class="hljs-string">&quot;yolov8s-640&quot;</span>)

json_sink = sv.JSONSink(<span class="hljs-string">&quot;out.json&quot;</span>)
<span class="hljs-keyword">with</span> json_sink <span class="hljs-keyword">as</span> sink:
    <span class="hljs-keyword">for</span> frame <span class="hljs-keyword">in</span> frames_generator:
        results = model.infer(frame)[<span class="hljs-number">0</span>]
        detections = sv.Detections.from_inference(results)
        sink.append(
            detections, custom_data={<span class="hljs-string">&quot;&lt;YOUR_LABEL&gt;&quot;</span>:<span class="hljs-string">&quot;&lt;YOUR_DATA&gt;&quot;</span>})<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div></div></div>  <div class="border-slate-200 lg:border-l lg:w-1/2 overflow-hidden"><div slot="col2" class="p-6 flex flex-col gap-4"><div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Run a fine-tuned LMM</h2> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="bash" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->pip install peft -q<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">from</span> inference.models.paligemma.paligemma <span class="hljs-keyword">import</span> PaliGemma
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image

image = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;dog.jpeg&quot;</span>)
prompt = <span class="hljs-string">&quot;Detect the dog.&quot;</span>

pg = PaliGemma(model_id= api_key=<span class="hljs-string">&quot;&lt;ROBOFLOW_API_KEY&gt;&quot;</span>)
results = pg.predict(image, prompt)

detections = sv.Detections.from_lmm(
    sv.LMM.PALIGEMMA,
    results,
    resolution_wh=(<span class="hljs-number">1000</span>, <span class="hljs-number">1000</span>),
    classes=[<span class="hljs-string">&quot;cat&quot;</span>, <span class="hljs-string">&quot;dog&quot;</span>]
)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Compute Metrics</h2> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->dataset = sv.DetectionDataset.from_yolo(<span class="hljs-string">&quot;&lt;PATH_TO_DATASET&gt;&quot;</span>)

model = get_model(<span class="hljs-string">&quot;yolov8s-640&quot;</span>)
<span class="hljs-keyword">def</span> <span class="hljs-title function_">callback</span>(<span class="hljs-params">image: np.ndarray</span>) -&gt; sv.Detections:
    results = model.infer(image)[<span class="hljs-number">0</span>]
    <span class="hljs-keyword">return</span> sv.Detections.from_inference(results)

confusion_matrix = sv.ConfusionMatrix.benchmark(
    dataset=dataset, callback=callback
)
<span class="hljs-built_in">print</span>(confusion_matrix.matrix)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div></div></div></div> </div>  <div class="w-full max-w-[1123px] pb-2 flex flex-col bg-white page-root overflow-hidden rounded-lg svelte-1ngqj27"> <div class="bg-[#8622FF] text-white text-2xl font-inter font-bold p-6"><h1>Utilities</h1></div>  <div class="flex-grow flex flex-col lg:flex-row lg:justify-evenly"> <div class="lg:w-1/2 overflow-hidden"><div slot="col1" class="p-6 flex flex-col gap-4"><div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> sv.Detections Operations</h2> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">Empty detections. Returned by every model when nothing is detected.</p> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->empty_detections = sv.Detections.empty()
<span class="hljs-keyword">if</span> empty_detections.is_empty():
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Nothing was detected!&quot;</span>)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">Count detected objects</p> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-built_in">len</span>(detections)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">Loop over detection results</p> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">for</span> xyxy, mask, confidence, class_id, tracker_id, data <span class="hljs-keyword">in</span> detections:
    <span class="hljs-built_in">print</span>(xyxy, mask, confidence, class_id, tracker_id, data)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">Filter detections by class</p> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->detections = sv.Detections.from_inference(results)
detections = detections[detections.class_id == <span class="hljs-number">0</span>]<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">Filter by class name</p> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->detections = sv.Detections.from_inference(results)
detections = detections[detections.data[<span class="hljs-string">&quot;class_name&quot;</span>] == <span class="hljs-string">&quot;cat&quot;</span>]<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">Merge multiple sv.Detections</p> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->detections1 = sv.Detections.from_inference(results1)
detections2 = sv.Detections.from_inference(results2)
merged_detections = sv.Detections.merge([detections1, detections2])<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Video Assets</h2> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">supervision provides a handful of videos for testing</p> <div class="bg-slate-300 relative"> <pre data-language="bash" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->pip install <span class="hljs-string">&quot;supervision[assets]&quot;</span> -q<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START --><span class="hljs-keyword">from</span> supervision.assets <span class="hljs-keyword">import</span> download_assets, VideoAssets

download_assets(VideoAssets.VEHICLES)
<span class="hljs-built_in">print</span>(VideoAssets.VEHICLES.value)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div></div></div>  <div class="border-slate-200 lg:border-l lg:w-1/2 overflow-hidden"><div slot="col2" class="p-6 flex flex-col gap-4"><div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> Image Utilities</h2> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">Crop image</p> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->cropped_image = sv.crop_image(image=image, xyxy=[<span class="hljs-number">200</span>, <span class="hljs-number">400</span>, <span class="hljs-number">600</span>, <span class="hljs-number">800</span>])<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">Scale image</p> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->scaled_image = sv.scale_image(image=image, scale_factor=<span class="hljs-number">0.5</span>)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">Resize image</p> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->resized_image = sv.resize_image(
    image=image, resolution_wh=(<span class="hljs-number">1000</span>, <span class="hljs-number">1000</span>), keep_aspect_ratio=<span class="hljs-literal">True</span>)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">Letterbox image (resize + pad)</p> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->letterboxed_image = sv.letterbox_image(
    image=image, resolution_wh=(<span class="hljs-number">1000</span>, <span class="hljs-number">1000</span>))<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">Overlay image</p> <div class="bg-slate-300 relative"> <pre data-language="python" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->overlay = np.zeros((<span class="hljs-number">400</span>, <span class="hljs-number">400</span>, <span class="hljs-number">3</span>), dtype=np.uint8)
resulting_image = sv.overlay_image(
    image=image, overlay=overlay, anchor=(<span class="hljs-number">200</span>, <span class="hljs-number">400</span>)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div> <div class="flex flex-col gap-4"><h2 class="text-xl font-inter"><span class="text-[#8622FF] ml-1 mb-1" data-svelte-h="svelte-t45480">›</span> for Google Colab</h2> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">Install custom branch of supervision</p> <div class="bg-slate-300 relative"> <pre data-language="bash" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->pip install git+https://github.com/YourName/supervision.git@your-branch<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">Display image in Colab by converting to PIL</p> <div class="bg-slate-300 relative"> <pre data-language="bash" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->sv.cv2_to_pillow(frame)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div> <div class="bg-[#f2e5ff] mb-2"><p class="text-xs opacity-90 p-2">Display image in Colab by plotting with matplotlib</p> <div class="bg-slate-300 relative"> <pre data-language="bash" class="text-xs opacity-85  svelte-1w9vok"><code class="hljs"><!-- HTML_TAG_START -->%matplotlib inline
sv.plot_image(frame)<!-- HTML_TAG_END --></code></pre>  <button class="copy-button svelte-1ip697x" data-svelte-h="svelte-frintc"><img src="./copy.svg" alt="Copy" class="w-4 h-4"></button></div> </div></div></div></div></div> </div></div> <footer class="w-full max-w-[1123px] mx-auto text-xs py-2 text-gray-400" data-svelte-h="svelte-1s6vobk">© 2024 Roboflow, Inc. All rights reserved.
</footer></div> <ul class="_toastContainer svelte-1u812xz"> </ul> 
			
			<script>
				{
					__sveltekit_1e0lgz = {
						base: new URL(".", location).pathname.slice(0, -1),
						assets: "/cheatsheet-supervision"
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("./_app/immutable/entry/start.DVWeqw6R.js"),
						import("./_app/immutable/entry/app.pbv2YX8K.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 2],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
	</body>
</html>
